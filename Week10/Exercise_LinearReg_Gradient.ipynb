{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression & Gradient Descent\n",
    "\n",
    "In this notebook we will work with the diabetes dataset \n",
    "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "https://web.stanford.edu/~hastie/Papers/LARS/diabetes.data (raw data, not standardised)\n",
    "\n",
    "The data set contains 10 baseline variables (X1, X2, X3....X10) for 442 patients with diabetes: age, sex, body mass index, average blood pressure, and six blood serum measurements. The target variable (y) indicates the progression of the dieases one year after baseline.\n",
    "\n",
    "Luckily, this database is available in sklearn, so we need only to load it. \n",
    "Even more luckily, the sklearn database is already standardised (compare with the raw data above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider a subset of the dataset, specifically only the variables: body mass index, average blood pressure and one blood serum measurement. Feel free to include more dimensions in your model. \n",
    "As usual insert your code in \"####ADD YOUR CODE HERE#####\" and answer the questions along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X = diabetes_X[:,2:5] #select only the 3 relevant features we want to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, we split our dataset in training set and test set (z.B 80 data points are left as a test).\n",
    "We will fit(train) our model on the training dataset and then we will evaluate how they really perform on test data.\n",
    "The performance on the test data is fundamental to see how models generalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X_train = diabetes_X[:-80] #feel free to change 80 to another value, you can also split data using the sklearn function: train_test_split\n",
    "diabetes_X_test = diabetes_X[-80:]\n",
    "\n",
    "diabetes_y_train = diabetes_y[:-80]\n",
    "diabetes_y_test = diabetes_y[-80:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we want to first compare several methods to determine the best parameters for our model. \n",
    "Let's start with the LinearRegression() function from sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "The LinearRegression class is based on the scipy.linalg.lstsq() function (the name stands for \"least squares\"), this compute the optimal paramters'values using the least square exact method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.####ADD YOUR CODE HERE#####\n",
    "\n",
    "#Once you defined your model, use the method .fit to fit to the data \n",
    "####ADD YOUR CODE HERE#####\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients (theta_1, theta_2, theta_3, theta_0): \\n')\n",
    "####ADD YOUR CODE HERE#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to compute the same parameters using the Batch Gradient Descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1  # learning rate, feel free to change\n",
    "n_iterations = 1000\n",
    "N = len(diabetes_X)\n",
    "\n",
    "theta_0 = np.random.randn(1) # random initialization\n",
    "theta_1 = np.random.randn(1)\n",
    "theta_2 = np.random.randn(1)\n",
    "theta_3 = np.random.randn(1)\n",
    "\n",
    "X1= diabetes_X_train[:,0]\n",
    "X2= diabetes_X_train[:,1]\n",
    "X3= diabetes_X_train[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code here the formulas for the batch gradient descent (check the lecture slides for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_iterations):\n",
    "\n",
    "    \n",
    "    gradient_theta_3 = ####ADD YOUR CODE HERE#####\n",
    "    gradient_theta_2 = ####ADD YOUR CODE HERE#####\n",
    "    gradient_theta_1 = ####ADD YOUR CODE HERE#####\n",
    "    gradient_theta_0 = ####ADD YOUR CODE HERE#####\n",
    "    \n",
    "    \n",
    "    theta_3 = ####ADD YOUR CODE HERE#####\n",
    "    theta_2 = ####ADD YOUR CODE HERE#####                              \n",
    "    theta_1 = ####ADD YOUR CODE HERE#####\n",
    "    theta_0 = ####ADD YOUR CODE HERE#####\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the parameters look like \n",
    "print(theta_1,theta_2,theta_3, theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the values obtained with the function LinearRegression().\n",
    "Try to change the number of iterations and/or eta to get closer to those values.\n",
    "\n",
    "Actually the best thing would be not to compare the parameters itself but the value of the cost function!\n",
    "Optional: Try to compute in both cases the cost function value. How do they compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "We try now to see how the results change if we use the SGD approach. We use here the sklearn function SGDRegressor.\n",
    "Check out here the syntax\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "This function has many parameters, for the moment just focus on the number of iterations and eta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg = ####ADD YOUR CODE HERE#####\n",
    "sgd_reg.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.coef_, sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare with the previous solutions? Try to adapt also here eta and number of iterations. \n",
    "How does it compare in terms of velocity with the Batch Gradient Descent?\n",
    "\n",
    "Try to run the previous 2 cells again. Do you get always the same result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you found the best parameters for your linear model, you can use them on the test data to predict values and evaluate how well your model perform, that is how much your predictions are off from the true y values of your test data.\n",
    "Let's start with the model obtained with LinearRegression() and then do the same with the linear regression obtained via SGD. \n",
    "How do the 2 compare on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code to obtain the model prediction for the test data, e.g. diabetes_X_test\n",
    "# for both cases, using the .predict method\n",
    "\n",
    "diabetes_y_pred_EasyLinReg = ####ADD YOUR CODE HERE#####\n",
    "diabetes_y_pred_SGD = ####ADD YOUR CODE HERE#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LinearRegression() Mean squared error: %.2f' % mean_squared_error(diabetes_y_test, diabetes_y_pred_EasyLinReg))\n",
    "print('SGD() Mean squared error: %.2f' % mean_squared_error(diabetes_y_test, diabetes_y_pred_SGD))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
