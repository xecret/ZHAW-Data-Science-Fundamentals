{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSV_OlCFKOD"
   },
   "source": [
    "# Training a neural network for Banknote Authenticity Detection with Tensorflow & Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTBSvHcSLBzc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will work with a dataset containing information about banknotes, to determines whether a banknote is fake or not. These information was extracted from images that were taken for the evaluation of an authentication procedure for banknotes.\n",
    "More details in:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n",
    "The list of features is:\n",
    "- Variance of Wavelet Transformed image (continuous).\n",
    "- Skewness of Wavelet Transformed image (continuous).\n",
    "- Kurtosis of Wavelet Transformed image (continuous).\n",
    "- Entropy of image (continuous).\n",
    "\n",
    "The last column of the dataset indicates the target variable (label), which is represented by the class a banknote belongs to:\n",
    "- Class (0 for authentic, 1 for inauthentic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first task define read the .csv file into a pandas dataframe called df_banknote. \n",
    "Pay attention that the original file doesnot include a header. For later convenience, while reading the file into the dataframe,\n",
    "you should also assign name to the column features, namely \"Variance\", \"Skewness\", \"Kurtosis\", \"Entropy\", \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_banknote = ### ADD CODE HERE####\n",
    "\n",
    "X = df_banknote.drop(['Class'],axis=1).values\n",
    "y = df_banknote['Class'].values\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X,y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the summary statistics of the dataset and get an idea of variable ranges and values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD CODE HERE #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_train = X_train_full[:150], X_train_full[150:] \n",
    "y_val, y_train = y_train_full[:150], y_train_full[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTFoji3INMEM"
   },
   "source": [
    "### Create and train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the main task is for you to define a Neural Network model!\n",
    "You decide to use a neural network model to build a classifier, which takes as input all available features (how many there are?) and predicts the most likely class, to which a sample belongs to. \n",
    "\n",
    "Write the code in the next cell to build a fully connected neural network composed by 2 hidden layers, with the following structure:\n",
    "-\tLayer 1: 16 nodes (or neurons), each with a Tanh activation function \n",
    "-\tLayer 2: 8 nodes (or neurons), each with a ReLU activation function  \n",
    "\n",
    "Attention: By choosing the properties of the output layer, take into account the information regarding the target variable and the type of problem you are dealing with (e.g. Regression?, Binary Classification? Multi-Class Classification?).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are almost there, what you need to do now it to choose the right loss function to use, depending on the type of problem you are dealing with. \n",
    "Insert this missing information in the cell under. \n",
    "\n",
    "Remember what we said in the class about the option 'from_logits'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=## ADD CODE HERE\n",
    "              ,optimizer=\"sgd\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time now to evaluate your model, of course on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check directly some single predictions from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[0:5]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using last week snippet from Logistic Regression notebook, implement the code that provide\n",
    "#you the confusion matrix. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/dm_python:dm_notebook3",
    "kind": "private"
   },
   "name": "tensorflow/datasets",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DSF_HS22",
   "language": "python",
   "name": "dsf_hs22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
